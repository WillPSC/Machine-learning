{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # import depedencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import Bunch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creation function bunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bunch(files: list, data: list):\n",
    "   bunch = Bunch(filenames = files, datas = data)\n",
    "   return bunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filenames</th>\n",
       "      <th>datas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alain_Madelin_702.txt</td>\n",
       "      <td>\\n\"Les Français ne veulent pas du match revanc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arlette_Laguiller_201.txt</td>\n",
       "      <td>\\nTravailleuses, Travailleurs, camarades et am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arlette_Laguiller_299.txt</td>\n",
       "      <td>\\nTravailleuses, travailleurs, camarades et am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arlette_Laguiller_38.txt</td>\n",
       "      <td>\\nTravailleuses, travailleurs, camarades et am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arlette_Laguiller_47.txt</td>\n",
       "      <td>\\nTravailleuses, Travailleurs, camarades et am...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   filenames  \\\n",
       "0      Alain_Madelin_702.txt   \n",
       "1  Arlette_Laguiller_201.txt   \n",
       "2  Arlette_Laguiller_299.txt   \n",
       "3   Arlette_Laguiller_38.txt   \n",
       "4   Arlette_Laguiller_47.txt   \n",
       "\n",
       "                                               datas  \n",
       "0  \\n\"Les Français ne veulent pas du match revanc...  \n",
       "1  \\nTravailleuses, Travailleurs, camarades et am...  \n",
       "2  \\nTravailleuses, travailleurs, camarades et am...  \n",
       "3  \\nTravailleuses, travailleurs, camarades et am...  \n",
       "4  \\nTravailleuses, Travailleurs, camarades et am...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textFile = []\n",
    "textData = []\n",
    "for file in os.listdir('discours/tous'):\n",
    "    textFile.append(file)\n",
    "    with open(f'discours/tous/{file}', 'r', encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "        textData.append(data)\n",
    "bunchs = create_bunch(textFile,textData)\n",
    "df = pd.DataFrame.from_dict(bunchs)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf-idf vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "def vectorisationTfIdf(data):\n",
    "    vect = TfidfVectorizer()\n",
    "    tfidf_matrix = vect.fit_transform(data)\n",
    "    return tfidf_matrix.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kmeans Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def kmeanModel(arrayMatrix, n_clusters):\n",
    "    kmeans = KMeans(n_clusters=n_clusters).fit(arrayMatrix)\n",
    "    return kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alain_Madelin_702.txt\n",
      "1\n",
      "Arlette_Laguiller_201.txt\n",
      "1\n",
      "Arlette_Laguiller_299.txt\n",
      "1\n",
      "Arlette_Laguiller_38.txt\n",
      "1\n",
      "Arlette_Laguiller_47.txt\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "kmeans1 = kmeanModel(vectorisationTfIdf(df['datas']), 2)\n",
    "\n",
    "for i in range(5):\n",
    "    print(df['filenames'][i])\n",
    "    print(kmeans1.labels_[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"fr_core_news_sm\")\n",
    "##remove pronoms in text \n",
    "all_stopwords = nlp.Defaults.stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy_processing(sentence):\n",
    "    #tokenize the sentence\n",
    "    mytokens = nlp(sentence)\n",
    "    #lemmatize the tokens\n",
    "    mytokens = [word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens]\n",
    "    #remove stopwords\n",
    "    mytokens = [word for word in mytokens if word not in all_stopwords and word not in string.punctuation]\n",
    "    mytokens = ' '.join(mytokens)\n",
    "    return mytokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()\n",
    "df2['datas'] = df2['datas'].apply(spacy_processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'français vouloir match revanch 1995 occasion dernier meeting campagne marseille alain madelin réunir responsable 250 comité soutien local occasion indiquer dernier ligne droite monde sentir bien passer chose ... déroute météo sondage chose aller déjouer pronostic formidable appétit changement vouloir escamoter débat tour réduire liberté choix français faire élection présidentiel an cohabitation inutile stérile match revanch 1995 bien oui passer chose français simplement vouloir -t ajouter débat escamoter traduire favoris médiatisation désaveu trouver confiance français ensemble montre formidable appétit changement evoquer programme alain madelin souligner français tort raison voir différence programme chirac programme jospin bien signe envier chose vote constructif résigner résignation tenter protestation inutile stérile abstention vouloir offrir vote espoir ambition vote utile constructif vote vrai changement rattraper temps perdre contrat confiance evoquer tour rappeler chèque blanc contrat confiance voix porter porteuse changement fort france besoin indispensable gagner voix faire confiance ... tromper gâcher fois ... faire peser poids conclure alain madelin 682'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df2['datas'][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0bd97771667a35e2d235e4a3379479b0c8422ae7b5443b3e391c39cc5f9e8c53"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
